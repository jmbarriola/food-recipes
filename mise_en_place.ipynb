{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def create_dict_from_pickle(filename):\n",
    "    return pd.read_pickle(filename)\n",
    "\n",
    "def filter_old_html(pages_dict, pattern='\\r\\n\\r\\n\\r\\n<!DOCTYPE html>'):\n",
    "    recipes_dict = {k: v for k, v in pages_dict.items() if not v.startswith(pattern)}\n",
    "    return recipes_dict\n",
    "\n",
    "def filter_non_recipes(pages_dict, pattern=\".*www.allrecipes.com/recipe/.*\"):\n",
    "    pattern = re.compile(pattern)\n",
    "    recipes_dict = {k: v for k, v in pages_dict.items() if pattern.match(k) and\n",
    "                    k != 'https://www.allrecipes.com/'}\n",
    "    return recipes_dict\n",
    "    \n",
    "def make_soup(recipe_tuple):\n",
    "    return (recipe_tuple[0], BeautifulSoup(recipe_tuple[1],\"html.parser\"))\n",
    "\n",
    "def get_recipe_json(soup):\n",
    "    recipe_json = json.loads(soup.find('script',  type=\"application/ld+json\").text)\n",
    "    return recipe_json\n",
    "\n",
    "def fetch_title(recipe_json):\n",
    "    return recipe_json[1]['name']\n",
    "\n",
    "def fetch_ingredients(recipe_json):\n",
    "    return recipe_json[1]['recipeIngredient']\n",
    "\n",
    "def fetch_steps(recipe_json):\n",
    "     # Ingredients list\n",
    "    steps_list = recipe_json[1]['recipeInstructions']\n",
    "    return [i['text'] for i in steps_list]\n",
    "\n",
    "def fetch_description(recipe_json):\n",
    "    return recipe_json[1]['description']\n",
    "\n",
    "def fetch_prep_time(recipe_json):\n",
    "    return recipe_json[1]['totalTime']\n",
    "\n",
    "def fetch_categories(recipe_json):\n",
    "    return recipe_json[1]['recipeCategory']\n",
    "    \n",
    "def fetch_nutrients(recipe_json, regex, nutrient_name):\n",
    "    # Extract name and strips whitespace\n",
    "    nutrition = recipe_json[1].get('nutrition')\n",
    "    nutrient = nutrition.get(nutrient_name) if nutrition is not None else None\n",
    "    return regex.search(nutrient).group() if nutrient is not None else None \n",
    "\n",
    "def fetch_rating_score(recipe_json):\n",
    "    return recipe_json[1]['aggregateRating'].get('ratingValue')\n",
    "\n",
    "def fetch_number_of_ratings(recipe_json):\n",
    "    return recipe_json[1]['aggregateRating'].get('ratingCount')\n",
    "\n",
    "def fetch_reviews_count(soup, regex):\n",
    "    reviews_count = soup.find('a',  class_=\"ugc-ratings-link ugc-reviews-link\")\n",
    "    return regex.search(reviews_count.text).group() if reviews_count is not None else None\n",
    "\n",
    "def fetch_reviews(recipe_json):\n",
    "    reviews_list = recipe_json[1]['review']\n",
    "    return [i['reviewBody'] for i in reviews_list]\n",
    "\n",
    "def fetch_photo_count(soup, regex):\n",
    "    photos = soup.find('a',  class_=\"ugc-ratings-link ugc-photos-link\")\n",
    "    return regex.search(photos.text).group() if photos is not None else None\n",
    "\n",
    "def mise_en_place(soup_tuple, regex=re.compile(\"\\d+.\\d*\")):\n",
    "    \n",
    "    link = soup_tuple[0]\n",
    "    soup = soup_tuple[1]\n",
    "    \n",
    "    recipe_json = get_recipe_json(soup)\n",
    "\n",
    "    # Recipe name \n",
    "    recipe_name = fetch_title(recipe_json)\n",
    "    \n",
    "    # Ingredients list\n",
    "    ingredients_list = fetch_ingredients(recipe_json)\n",
    "    \n",
    "    # Categories list\n",
    "    categories_list = fetch_categories(recipe_json)\n",
    "    \n",
    "    # Description\n",
    "    description = fetch_description(recipe_json)\n",
    "    \n",
    "    # Steps\n",
    "    steps = fetch_steps(recipe_json)\n",
    "    \n",
    "    # Nutritional info\n",
    "    # Calories\n",
    "    cal = fetch_nutrients(recipe_json, regex, nutrient_name=\"calories\")\n",
    "    # Fat\n",
    "    fat = fetch_nutrients(recipe_json, regex, nutrient_name=\"fatContent\")\n",
    "    # Carbs\n",
    "    carb = fetch_nutrients(recipe_json, regex, nutrient_name=\"carbohydrateContent\")\n",
    "    # Protein\n",
    "    prot = fetch_nutrients(recipe_json, regex, nutrient_name=\"proteinContent\")\n",
    "    # Cholesterol\n",
    "    chol = fetch_nutrients(recipe_json, regex, nutrient_name=\"cholesterolContent\")\n",
    "    # Sodium\n",
    "    sod = fetch_nutrients(recipe_json, regex, nutrient_name=\"sodiumContent\")\n",
    "    # Fiber\n",
    "    fiber = fetch_nutrients(recipe_json, regex, nutrient_name=\"fiberContent\")\n",
    "    # Saturated Fat\n",
    "    saturated_fat = fetch_nutrients(recipe_json, regex, nutrient_name=\"saturatedFatContent\")\n",
    "    # Sugar\n",
    "    sugar = fetch_nutrients(recipe_json, regex, nutrient_name=\"sugarContent\")\n",
    "    # Trans Fat\n",
    "    trans_fat = fetch_nutrients(recipe_json, regex, nutrient_name=\"transFatContent\")\n",
    "    # Trans Fat\n",
    "    unsaturated_fat = fetch_nutrients(recipe_json, regex, nutrient_name=\"unsaturatedFatContent\")\n",
    "    \n",
    "    # Prep Time\n",
    "    prep_time = fetch_prep_time(recipe_json)\n",
    "    prep_time = prep_time if prep_time is not None else prep_time \n",
    "    \n",
    "    \n",
    "    # Rating\n",
    "    number_of_ratings = fetch_number_of_ratings(recipe_json)\n",
    "    rating = fetch_rating_score(recipe_json)\n",
    "\n",
    "    # Reviews\n",
    "    num_reviews = fetch_reviews_count(soup, regex)\n",
    "    reviews = fetch_reviews(recipe_json)\n",
    "    \n",
    "    # Photos\n",
    "    photos = fetch_photo_count(soup, regex)\n",
    "    \n",
    "    \n",
    "    return {\"link\":link, \"recipe_name\":recipe_name,\"description\":description, \"ingredients_list\":ingredients_list,\n",
    "                \"categories_list\":categories_list,\"calories\":cal,\"fat\":fat,\"carbs\":carb, \"protein\":prot,\n",
    "                \"cholesterol\":chol,\"sodium\":sod, \"saturated_fat\":saturated_fat, \"sugar\":sugar, \"fiber\":fiber, \n",
    "                \"trans_fat\":trans_fat, \"unsaturated_fat\":unsaturated_fat,\"prep_time\":prep_time,\n",
    "                \"ratings_number\":number_of_ratings, \"rating_score\":rating, \"reviews_number\": num_reviews,\n",
    "                \"reviews\": reviews, \"photos_number\":photos, \"steps\":steps}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recipe_df(filename):\n",
    "    print('Reading file..')\n",
    "    pages_dict = create_dict_from_pickle(\"datasets/pickles/recipes_{}.p\".format(NAME))\n",
    "    print('Filtering old recipes pages')\n",
    "    recipes_dict = filter_old_html(pages_dict)\n",
    "    print('Filtering non recipes pages')\n",
    "    recipes_dict = filter_non_recipes(recipes_dict)\n",
    "    print('Creating soup dictionary')\n",
    "    soups_dict = dict(map(make_soup, recipes_dict.items()))\n",
    "    print('Extracting recipes info')\n",
    "    list_recipes_dict = list(map(mise_en_place, soups_dict.items()))\n",
    "    print('Creating dataframe')\n",
    "    return pd.DataFrame(list_recipes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/media/juan/DATA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"old_part5_2020_12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file..\n",
      "Filtering old recipes pages\n",
      "Filtering non recipes pages\n",
      "Creating soup dictionary\n",
      "Extracting recipes info\n",
      "Creating dataframe\n"
     ]
    }
   ],
   "source": [
    "df = create_recipe_df(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(661, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/juan/ds_projects/recipes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"datasets/dataframes/recipe_df_{}_new.csv\".format(NAME),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
